{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZ+jnfOj/0SzFX78NiVUNw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrutimunde10/SCT_ML_4/blob/main/Task4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWrQUAzhjoh_",
        "outputId": "d45b590c-6f71-43d4-d09d-c0a3a766b72c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the uploaded file\n",
        "uploaded_file_path = \"/content/drive/MyDrive/Colab Notebooks/AIML datasets/Task 4 datasetff.zip\"\n",
        "extracted_folder_path = \"/content/drive/MyDrive/Colab Notebooks/AIML datasets/Task 4 datasetff\"\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(uploaded_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder_path)\n",
        "\n",
        "# List the contents of the extracted folder\n",
        "extracted_contents = os.listdir(extracted_folder_path)\n",
        "extracted_contents\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG9xfP_ZueM7",
        "outputId": "35787ecd-186c-4978-ea10-fe47a26f5960"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dataset', 'Task 4 datasetff']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the main extracted folder\n",
        "dataset_folder_path = os.path.join(extracted_folder_path, 'Task 4 datasetff')\n",
        "\n",
        "# List the contents of the dataset folder\n",
        "dataset_contents = os.listdir(dataset_folder_path)\n",
        "dataset_contents\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpicdhwyu4dM",
        "outputId": "3c641577-06bf-46a2-988c-056632d65378"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dataset']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the 'dataset' folder\n",
        "dataset_path = os.path.join(dataset_folder_path, 'dataset')\n",
        "\n",
        "# List the contents of the 'dataset' folder\n",
        "gesture_categories = os.listdir(dataset_path)\n",
        "gesture_categories\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PydIVKDkwJ1i",
        "outputId": "bd30d124-8d02-41d9-e8f6-b0e3d94c0f76"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['training_set']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the 'training_set' folder\n",
        "training_set_path = os.path.join(dataset_path, 'training_set')\n",
        "\n",
        "# List the contents of the 'training_set' folder to check for gesture categories or other details\n",
        "training_set_contents = os.listdir(training_set_path)\n",
        "training_set_contents\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e80hQgfxwRSZ",
        "outputId": "26d81878-2b68-40f6-a305-ed15cb5783c9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['background', 'four', 'L', 'three', 'thumbsup', 'two', 'up']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Define a function to load the images and their corresponding labels\n",
        "def load_data(training_set_contents):\n",
        "    data = []\n",
        "    labels = []\n",
        "    categories = os.listdir(dataset_path)\n",
        "\n",
        "    for category in categories:\n",
        "        category_path = os.path.join(dataset_path, category)\n",
        "        if os.path.isdir(category_path):\n",
        "            for image_file in os.listdir(category_path):\n",
        "                image_path = os.path.join(category_path, image_file)\n",
        "\n",
        "                # Read and preprocess the image\n",
        "                image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/AIML datasets/Task 4 datasetff/Task 4 datasetff/dataset/training_set/L/l_gesture1000.png')\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                image = cv2.resize(image, (64, 64))  # Resize the image to 64x64\n",
        "                image = img_to_array(image)  # Convert to numpy array\n",
        "\n",
        "                data.append(image)\n",
        "                labels.append(category)  # The category (folder name) is the label\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    data = np.array(data, dtype=\"float32\")\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "# Load data\n",
        "data, labels = load_data(training_set_path)\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "data /= 255.0\n"
      ],
      "metadata": {
        "id": "MBxFasScwWDG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(128, (3, 3), activation=\"relu\"),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(np.unique(labels)), activation=\"softmax\")  # Output layer with as many neurons as gesture categories\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
        "print(f\"Validation Accuracy: {val_acc * 100:.2f}%\")\n",
        "\n",
        " # Predict on new image (example)\n",
        "def predict_gesture('/content/drive/MyDrive/Colab Notebooks/AIML datasets/Task 4 datasetff/Task 4 datasetff/dataset/training_set/L/l_gesture1002.png'):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (64, 64))\n",
        "    image = img_to_array(image)\n",
        "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "\n",
        "    prediction = model.predict(image)\n",
        "    predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])\n",
        "    return predicted_label[0]\n",
        "\n",
        "# Example usage\n",
        "gesture = predict_gesture(\"/content/drive/MyDrive/Colab Notebooks/AIML datasets/Task 4 datasetff/Task 4 datasetff/dataset/training_set/L/l_gesture1010.png\")\n",
        "print(f\"Predicted Gesture: {gesture}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "9Xoslhi8yrDC",
        "outputId": "e64ffecd-19da-48a5-bd89-0921e1aafc0f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-10-42846f936a54>, line 37)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-42846f936a54>\"\u001b[0;36m, line \u001b[0;32m37\u001b[0m\n\u001b[0;31m    def predict_gesture('/content/drive/MyDrive/Colab Notebooks/AIML datasets/Task 4 datasetff/Task 4 datasetff/dataset/training_set/L/l_gesture1002.png'):\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}